{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-09T08:47:45.526018Z",
     "start_time": "2024-12-09T08:45:52.351520Z"
    }
   },
   "source": [
    "# if you use word embeddings to represent text, provide the script for loading the embeddings below\n",
    "# if you use glove, word2vec or fasttext embeddings, please specify which version you use (e.g. glove.6B.300d)\n",
    "# if you use other embedding models, please provide the download link\n",
    "\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "path_of_downloaded_files = \"/MLOps/2.Propaganda_detection/glove.6B.300d.txt\"\n",
    "glove_file = datapath(path_of_downloaded_files)\n",
    "word2vec_glove_file = get_tmpfile(\"glove.6B.300d.txt\")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)\n",
    "word_vectors = KeyedVectors.load_word2vec_format(word2vec_glove_file)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-09T08:47:45.541541Z",
     "start_time": "2024-12-09T08:47:45.538924Z"
    }
   },
   "source": [
    "# scripts for creating sentence vectors; adjust the code if necessary\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "def vectorize_sent(word_vectors, sent, oov_vec):\n",
    "    word_vecs = []\n",
    "    for token in word_tokenize(sent): \n",
    "        if token not in word_vectors: \n",
    "            word_vecs.append(oov_vec)\n",
    "        else:\n",
    "            word_vecs.append(word_vectors[token].astype('float64'))\n",
    "    return np.mean(word_vecs,axis=0)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-09T08:45:51.638861Z",
     "start_time": "2024-12-09T08:45:51.634410Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 14,
   "source": [
    "# NOTE! The model defined below MUST BE EXACTLY THE SAME as the one you used at training\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, out_dim, dp_rate):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_dim, input_dim*2)\n",
    "        self.output_layer = nn.Linear(input_dim*2, out_dim)\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        z1 = self.dropout(x_in) # output of the input layer, after dropout\n",
    "        z2 = self.relu(self.hidden_layer(z1)) # output of the hidden layer\n",
    "        logits = self.output_layer(z2)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-09T08:47:45.564526Z",
     "start_time": "2024-12-09T08:47:45.561858Z"
    }
   },
   "source": [
    "# reconstruct your trained model from pickle\n",
    "\n",
    "import pickle\n",
    "def reconstruct_model(pickle_path):\n",
    "    saved_model_dic = pickle.load(open(pickle_path,\"rb\"))\n",
    "    input_dim = saved_model_dic['input_dim']\n",
    "    dp_rate = saved_model_dic['dropout_rate']\n",
    "    output_dim = 2\n",
    "    model = MLP(input_dim, output_dim, dp_rate)\n",
    "    saved_weights = saved_model_dic['neural_weights']\n",
    "    model.load_state_dict(saved_weights)\n",
    "    oov_vec = saved_model_dic['oov_vector']\n",
    "    \n",
    "    return model, oov_vec"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-09T08:47:45.570944Z",
     "start_time": "2024-12-09T08:47:45.568455Z"
    }
   },
   "source": [
    "# use the reconstructed model to make predictions on the test data\n",
    "\n",
    "def test_trained_model(model, oov_vec, test_text):\n",
    "    test_vecs = [vectorize_sent(word_vectors, ss, oov_vec ) for ss in test_text]\n",
    "    test_vecs_tensor = torch.tensor(test_vecs, dtype=torch.float)\n",
    "    test_prediction = model(test_vecs_tensor)\n",
    "    pred_labels = [np.argmax(tp.detach().numpy()) for tp in test_prediction]\n",
    "    return pred_labels"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-09T08:47:46.001073Z",
     "start_time": "2024-12-09T08:47:45.581174Z"
    }
   },
   "source": [
    "# load sample test data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "test_data = pd.read_table('train.tsv')\n",
    "test_text = test_data['sentence_text'].tolist()[-2000:]\n",
    "test_raw_labels = test_data['label'].tolist()[-2000:]\n",
    "label_dic = {'non-propaganda':0, 'propaganda':1}\n",
    "test_labels = [label_dic[rl] for rl in test_raw_labels]\n",
    "\n",
    "print('test data size', len(test_labels))\n",
    "\n",
    "# reconstruct model and make predictions\n",
    "model, oov_vec = reconstruct_model('propoganda.pickle')\n",
    "test_pred = test_trained_model(model, oov_vec, test_text)\n",
    "\n",
    "# test model\n",
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score\n",
    "pre, rec, f1, _ = precision_recall_fscore_support(test_labels, test_pred, average='macro')\n",
    "print('macro-F1 on test data', f1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data size 2000\n",
      "macro-F1 on test data 0.6169517780172413\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T08:53:55.550798Z",
     "start_time": "2024-12-09T08:53:55.546461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_query(model, word_vectors, oov_vec, query):\n",
    "    query_vec = vectorize_sent(word_vectors, query, oov_vec)\n",
    "    query_tensor = torch.tensor([query_vec], dtype=torch.float)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        prediction = model(query_tensor)\n",
    "        pred_label = torch.argmax(prediction, dim=1).item()\n",
    "    return pred_label"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T08:57:20.088104Z",
     "start_time": "2024-12-09T08:57:18.368136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model, oov_vec = reconstruct_model('propoganda.pickle')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query = input(\"Enter the query: \")\n",
    "    pred_labels = predict_query(model,word_vectors, oov_vec, query)\n",
    "    label_map = {0: \"non-propaganda\", 1: \"propaganda\"}\n",
    "    print(f\"{label_map[pred_labels]}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-propaganda\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
